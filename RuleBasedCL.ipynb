{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import csv\n",
    "import spacy\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is a rule based classfier to detect quotes and lyrics based on the names and content of the website, the evaluation of the classifer is in MLClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A morning filled with the goodness of God's pe...</td>\n",
       "      <td>https://www.pinterest.co.uk/pin/12434163968566...</td>\n",
       "      <td>May your day be filled with the blessings of l...</td>\n",
       "      <td>Wishing you a day filled with the deepest bles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A morning filled with the goodness of God's pe...</td>\n",
       "      <td>https://www.pinterest.co.uk/barbarajstone3/mor...</td>\n",
       "      <td>386 best Morning Coffee with God! images on Pi...</td>\n",
       "      <td>Sep 28, 2018- Explore Barbara Stone's board \"M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A morning filled with the goodness of God's pe...</td>\n",
       "      <td>http://www.quotegarden.com/coffee.html</td>\n",
       "      <td>Coffee Quotes, Sayings about Caffeine - The Qu...</td>\n",
       "      <td>16 Feb 2018 - The morning cup of coffee has an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  A morning filled with the goodness of God's pe...   \n",
       "1  A morning filled with the goodness of God's pe...   \n",
       "2  A morning filled with the goodness of God's pe...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.pinterest.co.uk/pin/12434163968566...   \n",
       "1  https://www.pinterest.co.uk/barbarajstone3/mor...   \n",
       "2             http://www.quotegarden.com/coffee.html   \n",
       "\n",
       "                                                name  \\\n",
       "0  May your day be filled with the blessings of l...   \n",
       "1  386 best Morning Coffee with God! images on Pi...   \n",
       "2  Coffee Quotes, Sayings about Caffeine - The Qu...   \n",
       "\n",
       "                                         description  \n",
       "0  Wishing you a day filled with the deepest bles...  \n",
       "1  Sep 28, 2018- Explore Barbara Stone's board \"M...  \n",
       "2  16 Feb 2018 - The morning cup of coffee has an...  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = pd.read_csv('./Data/all.csv')\n",
    "file[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39041\n"
     ]
    }
   ],
   "source": [
    "print(len(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocess data: the preprocess here is just lower case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tokenize\n",
    "def preprocess(sent):\n",
    "    words = str(sent).lower().split()\n",
    "    new_words = []\n",
    "    for w in words:\n",
    "        w = re.sub(r'[0-9]+', '', w)\n",
    "        new_words.append(w)\n",
    "        \n",
    "    return ' '.join(new_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load spacy model\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Here we create a class to store each variable as an object \n",
    "2. Return the count of key words 'lyric, lyrics, quote, quotes' in the name of the website, because the name of the website contains most of the information we need\n",
    "3. Count the keywords and store it as Score. Score is a vector that contain keyword counts in each search result\n",
    "4. compute cosine similarity between post and retrieve website content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class myQuote:\n",
    "    def __init__(self, text):\n",
    "        #read in CSV, process\n",
    "        self.quoteText = text\n",
    "        self.quoteID = hash(self.quoteText)\n",
    "        self.link = []\n",
    "        self.name = []\n",
    "        self.description = []\n",
    "        self.scores = []\n",
    "        self.cos = []\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return self.quoteID\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Object text: \" + self.quoteText + '\\n' +\\\n",
    "        \"Links: \" + str(self.link) + '\\n' +\\\n",
    "        \"Names: \" + str(self.name) + '\\n' +\\\n",
    "        \"Description \" + str(self.description) + '\\n' +\\\n",
    "        \"Scores: \" + str(self.scores)\n",
    "        \n",
    "\n",
    "objects = {}\n",
    "with open('./Data/all.csv', 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        #print(row['text'])\n",
    "        texthash = hash(row['text'])\n",
    "        if texthash not in objects:\n",
    "            objects[texthash] = myQuote(row['text'])\n",
    "        objects[texthash].link.append(row['link'])\n",
    "        objects[texthash].name.append(row['name'])\n",
    "        objects[texthash].description.append(row['description'])\n",
    "        line = preprocess(row['name'])\n",
    "        #count keywords\n",
    "        count = line.count(\"lyric\") + line.count(\"lyrics\") + line.count(\"quote\") + line.count(\"quotes\")\n",
    "        objects[texthash].scores.append(count)\n",
    "   \n",
    "  \n",
    "        #add extra fields in the class if I need to add more fields        \n",
    "#print(len(objects.keys()))\n",
    "#for item in objects.keys():\n",
    "#    if sum(objects[item].scores) > 0:\n",
    "#        print(objects[item])\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and now i realisei shouldve kissed you in labut i drove home all aloneas if i had a choice anyway'"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add cosine similarity as an object\n",
    "#remove punctionations\n",
    "def preprocess2(sent):\n",
    "    #remove punctustion\n",
    "    sent = re.sub(r'[^\\w\\s]','',sent)\n",
    "    words = sent.split()\n",
    "    new_words = []\n",
    "    for w in words:      \n",
    "        new_words.append(w.lower())\n",
    "        \n",
    "    return ' '.join(new_words)\n",
    "\n",
    "s = '? And now I realise//I should\\'ve kissed you in LA//But I drove home all alone//As if I had a choice anyway~ ?'\n",
    "preprocess2(s)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosineSim(results):\n",
    "    for item in results:\n",
    "        str1 = ''.join (objects[item].description)\n",
    "        doc2 = nlp(preprocess2(str1))\n",
    "        doc1 = nlp(preprocess2(objects[item].quoteText))\n",
    "        objects[item].cos.append(doc1.similarity(doc2))\n",
    "\n",
    "cosineSim(results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#here we save the file as csv, the csv file is just for your reference\n",
    "def saveAsCSV(dictz,filename):\n",
    "    f = open(filename, 'w')\n",
    "    writer = csv.writer(f, delimiter = ',',quoting=csv.QUOTE_MINIMAL)  \n",
    "    writer.writerow([\"hash\"] + [\"text\"] + [\"count\"] + [\"cosineSim\"])\n",
    "    for item in objects.keys():\n",
    "        writer.writerow([objects[item].quoteID] + [objects[item].quoteText] + [objects[item].scores] + [objects[item].cos])\n",
    "    f.close()\n",
    "    \n",
    "saveAsCSV(objects, 'myprocessedquotes2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  compute cosine similarity between posts and content (description) of the search result, those with 90% above similarity are labeled as quote. Those less than 92% are labeled as suspect.\n",
    "2. cosine similarity >= 96%, label it as quote\n",
    "3. cosine similarity > 92% but < 96% \n",
    "    1. Count keywords in search results (link names), if result contains keywords in  more than two document, label it as quote\n",
    "    2. otherwise label it as suspect "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model:\n",
    "In the evaluation set\n",
    "Among 200 posts: 24 suspect, 25 quotes\n",
    "4 in 24 are actual quotes\n",
    "2 among the rest is actual quote\n",
    "\n",
    "Precision: 25/25 = 1\n",
    "Recall: 25/31 = 0.81\n",
    "F = 2(1*0.81/1+0.81) = 0.895"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use cosine similarity to compare text with search result\n",
    "nlp = spacy.load('en')\n",
    "def SearchResult2(results, filename):\n",
    "    f = open(filename, 'w')\n",
    "    writer = csv.writer(f, delimiter = ',',quoting=csv.QUOTE_MINIMAL)  \n",
    "    writer.writerow([\"hash\"] + [\"text\"] + [\"count\"]+ [\"cosineSim\"] +['label'])\n",
    "    for item in results:\n",
    "        if objects[item].cos[0] < 0.92:\n",
    "            writer.writerow([objects[item].quoteID] + [objects[item].quoteText] + [objects[item].scores] + [objects[item].cos[0]]+['NotQuote'])\n",
    "        elif objects[item].cos[0] > 0.92 and objects[item].cos[0] < 0.96:\n",
    "            count = 0\n",
    "            for score in objects[item].scores:\n",
    "                if score > 1: # 1 is 0 before we add 1 for smoothing\n",
    "                    count = count + 1\n",
    "            if count >= 2 :\n",
    "                writer.writerow([objects[item].quoteID] + [objects[item].quoteText] + [objects[item].scores] + [objects[item].cos[0]]+['quote'])\n",
    "            else:\n",
    "                writer.writerow([objects[item].quoteID] + [objects[item].quoteText] + [objects[item].scores] + [objects[item].cos[0]]+['suspect'])\n",
    "        else:\n",
    "            writer.writerow([objects[item].quoteID] + [objects[item].quoteText] + [objects[item].scores] + [objects[item].cos[0]]+['quote'])\n",
    "   # else:\n",
    "       # writer.writerow([objects[item].quoteID] + [objects[item].quoteText] + [objects[item].scores] + ['null']+['NotQuote'])\n",
    "    f.close()\n",
    "        \n",
    "results = objects.keys()\n",
    "SearchResult2(results, 'QuotesDetected_all3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing features for ML models:\n",
    "Not all the queries have the same number of results, now we align the result vector as 10, which means we packed the result vector to 10 with 0. 10 is the maxium results in the entries. \n",
    "But before we algin the vector, we smooth the score results by adding 1, then the empty result is represented by 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def align_scores(objects):\n",
    "    for item in objects:\n",
    "        count = 0\n",
    "        for i in range(len(objects[item].scores)): # add 1 to all the scores \n",
    "            objects[item].scores[i] = objects[item].scores[i] +1           \n",
    "            if objects[item].scores[i] is not None:\n",
    "                count = count + 1 \n",
    "               # score = score + 1 won't work because score is a shallow copy\n",
    "        #print(objects[item].scores)\n",
    "        while count < 10:\n",
    "            objects[item].scores.append(0) #empty result is replaced by 0\n",
    "            count = count + 1\n",
    "\n",
    "align_scores(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7931760405938567, 0.8392104624625699, 0.8795039632197936, 0.888068735773229, 0.892343830554656, 0.8931492717445956, 0.9015202272173928, 0.8983867934509157, 0.8956870011771089]\n",
      "[0.9477222853011377, 0.9521458047100916, 0.9683161510072209, 0.9696274644433669, 0.9701125256993208, 0.971699710442211, 0.9724184061024539, 0.9674229419573442, 0.9670316158573239]\n",
      "[0.9642679429616342, 0.9500276671597974, 0.9355095071756162, 0.9348746336805109, 0.9380975214108219, 0.9258982356962796, 0.9369188294523213, 0.9412716534469636, 0.9433237704986305]\n",
      "[0.951290419812904, 0.9434646085106638, 0.9439693019234673, 0.9515647217395145, 0.9485525749001547, 0.9497238215336847, 0.9503412892497236, 0.9495074453693616, 0.9491427003586426, 0.9408861415235144]\n"
     ]
    }
   ],
   "source": [
    "#now let's see the aligned vectors\n",
    "count = 0\n",
    "for item in results:\n",
    "    print(objects[item].scores)\n",
    "    count = count + 1\n",
    "    if count > 3:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dump object to pickles\n",
    "import pickle\n",
    "\n",
    "filename = 'searchResults_Multicos'\n",
    "outfile = open(filename,'wb')\n",
    "\n",
    "pickle.dump(objects,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this function prints the result from the model and the algined vectors\n",
    "def printFeatures(results, filename):\n",
    "    SearchResult2(results, 'temp.csv')\n",
    "        \n",
    "printFeatures(results, 'features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###rehash object so that each post compare with each piece of text from the website\n",
    "class myQuote:\n",
    "    def __init__(self, text):\n",
    "        #read in CSV, process\n",
    "        self.quoteText = text\n",
    "        self.quoteID = hash(self.quoteText)\n",
    "        self.link = []\n",
    "        self.name = []\n",
    "        self.description = []\n",
    "        self.scores = []\n",
    "        self.cos = []\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return self.quoteID\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Object text: \" + self.quoteText + '\\n' +\\\n",
    "        \"Links: \" + str(self.link) + '\\n' +\\\n",
    "        \"Names: \" + str(self.name) + '\\n' +\\\n",
    "        \"Description \" + str(self.description) + '\\n' +\\\n",
    "        \"Scores: \" + str(self.scores)\n",
    "        \n",
    "\n",
    "objects2 = {}\n",
    "with open('./Data/all.csv', 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        #print(row['text'])\n",
    "        texthash = hash(row['text'])\n",
    "        if texthash not in objects2:\n",
    "            objects2[texthash] = myQuote(row['text'])\n",
    "        objects2[texthash].link.append(row['link'])\n",
    "        objects2[texthash].name.append(row['name'])\n",
    "        objects2[texthash].description.append(row['description'])\n",
    "        line = preprocess(row['name'])\n",
    "        #count keywords\n",
    "        count = line.count(\"lyric\") + line.count(\"lyrics\") + line.count(\"quote\") + line.count(\"quotes\")\n",
    "        objects2[texthash].scores.append(count)\n",
    "        str1 = ''.join (objects2[texthash].description)\n",
    "        doc2 = nlp(preprocess2(str1))\n",
    "        doc1 = nlp(preprocess2(objects2[texthash].quoteText))\n",
    "        objects2[texthash].cos.append(doc1.similarity(doc2))\n",
    "  \n",
    "        #add extra fields in the class if I need to add more fields        \n",
    "#print(len(objects.keys()))\n",
    "#for item in objects.keys():\n",
    "#    if sum(objects[item].scores) > 0:\n",
    "#        print(objects[item])\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#packed the cosine similarity space to 10\n",
    "def align_cosSim(objects):\n",
    "    for item in objects:\n",
    "        count = 0\n",
    "        for i in range(len(objects[item].cos)):           \n",
    "            if objects[item].cos is not None:\n",
    "                count = count + 1 \n",
    "               # score = score + 1 won't work because score is a shallow copy\n",
    "        #print(objects[item].scores)\n",
    "        while count < 10:\n",
    "            objects[item].cos.append(0) #empty result is replaced by 0\n",
    "            count = count + 1\n",
    "            \n",
    "align_scores(objects2)\n",
    "#align_cosSim(objects2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 5, 7, 5, 7, 1, 1, 6, 0] [0.8121557512130518, 0.8444628731297248, 0.883238498061439, 0.895255415804191, 0.8973190794659642, 0.9020793257695144, 0.9103472948899834, 0.9065849742168149, 0.9014258540138601, 0]\n",
      "[5, 2, 3, 1, 1, 1, 1, 1, 3, 0] [0.9661760927270792, 0.9684345513806265, 0.9793349898739949, 0.9772083674557045, 0.9790977629789119, 0.9809415528730745, 0.981144944743423, 0.9778870115542392, 0.9769993154201844, 0]\n",
      "[5, 7, 3, 5, 9, 9, 5, 1, 1, 0] [0.9697538260187835, 0.968014513297105, 0.9508086657467949, 0.9540593281024805, 0.9596373683815872, 0.9656340173608626, 0.9688343753683547, 0.971085906620613, 0.9686464488537065, 0]\n",
      "[1, 1, 1, 1, 3, 1, 1, 1, 1, 3] [0.9741191505979864, 0.9702187708300353, 0.9585112444665423, 0.9671731587604064, 0.9668505532633145, 0.9619517474723219, 0.9628368766147921, 0.9623696406210958, 0.9611158616321533, 0.9562258392623101]\n"
     ]
    }
   ],
   "source": [
    "#now let's see the aligned vectors\n",
    "count = 0\n",
    "for item in objects2:\n",
    "    print(objects2[item].scores, objects2[item].cos)\n",
    "    count = count + 1\n",
    "    if count > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dump object to pickles\n",
    "filename = 'searchResults_Multicos'\n",
    "outfile = open(filename,'wb')\n",
    "\n",
    "pickle.dump(objects2,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
